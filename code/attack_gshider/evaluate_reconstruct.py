import numpy as np
import torch
import os
import sys
import matplotlib.pyplot as plt
from argparse import ArgumentParser
from plyfile import PlyData
import torch.nn as nn

# ä»æ‚¨çš„é¡¹ç›®ä¸­å¯¼å…¥å¿…è¦çš„æ¨¡å—
from scene import Scene, GaussianModel
from gaussian_renderer import render
from arguments import ModelParams, OptimizationParams, PipelineParams
from utils.general_utils import safe_state
from decoder import SimpleCNN  # [æ–°å¢] å¯¼å…¥RGBè§£ç å™¨

# å¯¼å…¥ç”¨äºè®¡ç®—æŒ‡æ ‡çš„åº“
import torchmetrics
os.environ['CUDA_VISIBLE_DEVICES'] = '1'

# --- 1. è¾…åŠ©å‡½æ•°ï¼šå¤ç”¨PLYåŠ è½½é€»è¾‘ (æ ¹æ®æ‚¨çš„ä»£ç åšäº†å¾®è°ƒä»¥å…¼å®¹ä¸¤ç§ç‰¹å¾) ---
def load_ply_as_initialization(ply_path, dataset, opt):
    gaussians = GaussianModel(dataset.sh_degree)
    try:
        plydata = PlyData.read(ply_path)
    except Exception as e:
        print(f"[é”™è¯¯] æ— æ³•è¯»å– PLY æ–‡ä»¶: {ply_path}ã€‚é”™è¯¯: {e}")
        sys.exit(1)

    data = plydata.elements[0].data

    xyz = np.stack((data['x'], data['y'], data['z'])).transpose()
    opacities = data['opacity'].reshape(-1, 1)
    scales = np.stack([data[f'scale_{i}'] for i in range(3)]).transpose()
    rots = np.stack([data[f'rot_{i}'] for i in range(4)]).transpose()

    # å…¼å®¹æ‚¨çš„ semantic_feature (GS-Hider) å’Œ features_dc (GaussianMarker)
    if 'semantic_0' in data.dtype.names:
        print("[ä¿¡æ¯] åœ¨ PLY æ–‡ä»¶ä¸­æ£€æµ‹åˆ° 'semantic_' ç‰¹å¾ã€‚")
        semantic_feature_names = [name for name in data.dtype.names if name.startswith('semantic_')]
        semantic_dim = len(semantic_feature_names)
        semantic_features = np.stack([data[name] for name in semantic_feature_names]).transpose()
        gaussians._semantic_feature = nn.Parameter(
            torch.tensor(semantic_features, dtype=torch.float, device="cuda").reshape(-1, 1,
                                                                                      semantic_dim).requires_grad_(
                True))
    elif 'f_dc_0' in data.dtype.names:
        print("[ä¿¡æ¯] åœ¨ PLY æ–‡ä»¶ä¸­æ£€æµ‹åˆ° 'f_dc' ç‰¹å¾ã€‚")
        features_dc = np.stack([data[f'f_dc_{i}'] for i in range(3)]).transpose()
        features_rest = np.stack([data[f'f_rest_{i}'] for i in range(48)]).transpose()
        gaussians._features_dc = nn.Parameter(
            torch.tensor(features_dc, dtype=torch.float, device="cuda").transpose(1, 2).contiguous().requires_grad_(
                True))
        gaussians._features_rest = nn.Parameter(
            torch.tensor(features_rest, dtype=torch.float, device="cuda").transpose(1, 2).contiguous().requires_grad_(
                True))
    else:
        raise ValueError(f"é”™è¯¯: PLY æ–‡ä»¶ '{ply_path}' ä¸­æ‰¾ä¸åˆ°å¯è¯†åˆ«çš„ç‰¹å¾å±æ€§ ('semantic_' æˆ– 'f_dc')ã€‚")

    gaussians._xyz = nn.Parameter(torch.tensor(xyz, dtype=torch.float, device="cuda").requires_grad_(True))
    gaussians._opacity = nn.Parameter(torch.tensor(opacities, dtype=torch.float, device="cuda").requires_grad_(True))
    gaussians._scaling = nn.Parameter(torch.tensor(scales, dtype=torch.float, device="cuda").requires_grad_(True))
    gaussians._rotation = nn.Parameter(torch.tensor(rots, dtype=torch.float, device="cuda").requires_grad_(True))
    gaussians.training_setup(opt)
    return gaussians


# --- 2. ä¸»è¯„ä¼°å‡½æ•° ---
def calculate_rgb_metrics(dataset, opt, pipe, ply_path, checkpoint_path):
    """
    åŠ è½½é‡å»ºçš„3DGSæ¨¡å‹å’ŒRGBè§£ç å™¨ï¼Œä¸åŸå§‹æ¨¡å‹çš„æ¸²æŸ“å›¾è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶è®¡ç®—è§†è§‰è´¨é‡æŒ‡æ ‡ã€‚
    """
    print("\n[ä¿¡æ¯] æ­£åœ¨åˆå§‹åŒ–åœºæ™¯å’Œæ¨¡å‹ç”¨äºæŒ‡æ ‡è®¡ç®—...")

    # --- åœºæ™¯åŠ è½½ (åŠ è½½ xx_wm çš„åœºæ™¯ä»¥è·å– GT å›¾åƒå’Œç›¸æœº) ---
    scene = Scene(dataset, GaussianModel(dataset.sh_degree), shuffle=False)

    # --- æ¨¡å‹åŠ è½½ ---
    # 1. åŠ è½½ä½ äºŒæ¬¡è®­ç»ƒå¥½çš„ xx_reconstruct æ¨¡å‹
    print(f"\n[ä¿¡æ¯] æ­£åœ¨ä» PLY æ–‡ä»¶åŠ è½½é‡å»ºçš„ 3DGS æ¨¡å‹: {ply_path}")
    reconstructed_gaussians = load_ply_as_initialization(ply_path, dataset, opt)

    # 2. [æ–°å¢] åŠ è½½é¢„è®­ç»ƒçš„ RGB è§£ç å™¨ (imagenet)
    imagenet = SimpleCNN().cuda()
    net_checkpoint_path = checkpoint_path.replace('.pth', '_net.pth')
    if os.path.exists(net_checkpoint_path):
        imagenet.load_state_dict(torch.load(net_checkpoint_path, map_location="cuda"))
        print(f"[ä¿¡æ¯] æˆåŠŸä»ä»¥ä¸‹è·¯å¾„åŠ è½½ RGB è§£ç å™¨: {net_checkpoint_path}")
    else:
        print(f"[é”™è¯¯] RGB è§£ç å™¨æƒé‡æ–‡ä»¶æœªæ‰¾åˆ°: {net_checkpoint_path}")
        return
    imagenet.eval()  # è®¾ä¸ºè¯„ä¼°æ¨¡å¼

    # --- è¯„ä¼°å‡†å¤‡ ---
    test_cameras = scene.getTrainCameras()

    bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]
    background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")

    total_ssim, total_psnr, total_mse = 0.0, 0.0, 0.0
    num_cameras = len(test_cameras)

    print(f"\n[ä¿¡æ¯] å¼€å§‹åœ¨ {num_cameras} ä¸ªç›¸æœºè§†è§’ä¸Šè¿›è¡Œè¯„ä¼°...")

    # --- å¾ªç¯è¯„ä¼° ---
    with torch.no_grad():
        for i, viewpoint_cam in enumerate(test_cameras):
            # A. æ¸²æŸ“ "é‡å»ºæ¨¡å‹" çš„ç‰¹å¾å›¾
            render_pkg = render(viewpoint_cam, reconstructed_gaussians, pipe, background)
            feature_map_reconstruct = render_pkg["render"]

            # B. [æ–°å¢] ä½¿ç”¨è§£ç å™¨å°†ç‰¹å¾å›¾è§£ç ä¸º "é‡å»ºRGBå›¾"
            rendered_rgb_image = imagenet(feature_map_reconstruct.unsqueeze(0)).squeeze(0)
            rendered_rgb_image = torch.clamp(rendered_rgb_image, 0.0, 1.0)

            # C. è·å– "åŸºå‡†çœŸå€¼å›¾" (å³ xx_wm çš„æœ€ç»ˆæ¸²æŸ“å›¾)
            gt_image = torch.clamp(viewpoint_cam.original_image.to("cuda"), 0.0, 1.0)

            # ç¡®ä¿å°ºå¯¸ä¸€è‡´
            if rendered_rgb_image.shape != gt_image.shape:
                gt_image = torch.nn.functional.interpolate(gt_image.unsqueeze(0),
                                                           size=rendered_rgb_image.shape[1:]).squeeze(0)

            # å‡†å¤‡æ•°æ®è¿›è¡ŒæŒ‡æ ‡è®¡ç®—
            rendered_batch = rendered_rgb_image.unsqueeze(0)
            gt_batch = gt_image.unsqueeze(0)

            # è®¡ç®—æŒ‡æ ‡
            ssim_val = torchmetrics.functional.structural_similarity_index_measure(rendered_batch, gt_batch,
                                                                                   data_range=1.0)
            psnr_val = torchmetrics.functional.peak_signal_noise_ratio(rendered_batch, gt_batch, data_range=1.0)
            mse_val = torch.nn.functional.mse_loss(rendered_batch, gt_batch)

            total_ssim += ssim_val.item()
            total_psnr += psnr_val.item()
            total_mse += mse_val.item()

            print(f"  è¯„ä¼°è§†è§’ {i + 1}/{num_cameras}: PSNR={psnr_val.item():.2f}, SSIM={ssim_val.item():.4f}")

            # æ˜¾ç¤ºç¬¬ä¸€å¼ å›¾çš„å¯¹æ¯”
            if i % 50 == 0:
                fig, axes = plt.subplots(1, 2, figsize=(12, 6))
                axes[0].imshow(gt_image.cpu().numpy().transpose(1, 2, 0))
                axes[0].set_title("Ground Truth RGB (from xx_wm)")
                axes[0].axis('off')
                axes[1].imshow(rendered_rgb_image.cpu().numpy().transpose(1, 2, 0))
                axes[1].set_title("Reconstructed RGB (from xx_reconstruct)")
                axes[1].axis('off')
                plt.show()

    # --- è®¡ç®—å¹¶æ‰“å°å¹³å‡ç»“æœ ---
    avg_ssim = total_ssim / num_cameras
    avg_psnr = total_psnr / num_cameras
    avg_mse = total_mse / num_cameras

    print("\n--- ğŸ“Š æœ€ç»ˆå¹³å‡è§†è§‰è´¨é‡æŒ‡æ ‡ ---")
    print(f"  - å¹³å‡ SSIM: {avg_ssim:.4f}  (è¶Šé«˜è¶Šå¥½, 1.0ä¸ºå®Œç¾)")
    print(f"  - å¹³å‡ PSNR: {avg_psnr:.2f} dB (è¶Šé«˜è¶Šå¥½)")
    print(f"  - å¹³å‡ MSE:  {avg_mse:.6f} (è¶Šä½è¶Šå¥½)")
    print("------------------------------------")


if __name__ == "__main__":
    parser = ArgumentParser(description="è¯„ä¼°äºŒæ¬¡è®­ç»ƒå3DGSæ¨¡å‹çš„RGBé‡å»ºè´¨é‡")
    lp = ModelParams(parser)
    op = OptimizationParams(parser)
    pp = PipelineParams(parser)

    # [ä¿®æ”¹] æ·»åŠ äº† --checkpoint_path ç”¨äºåŠ è½½è§£ç å™¨
    parser.add_argument("--ply_path", type=str, default="output/trex_attack/merged_gaussians/point_cloud/iteration_2000/point_cloud.ply",
                        help="æŒ‡å‘ xx_reconstruct æ¨¡å‹çš„ .ply æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--checkpoint_path", type=str, default="output/trex_wm/chkpnt10000.pth",
                        help="æŒ‡å‘åŸå§‹ xx_wm æ¨¡å‹çš„ .pth æ£€æŸ¥ç‚¹æ–‡ä»¶ (ç”¨äºåŠ è½½è§£ç å™¨æƒé‡)")
    parser.add_argument("--quiet", action="store_true")

    # å‘½ä»¤è¡Œè¿è¡Œç¤ºä¾‹:
    # python evaluate_reconstruction_v2.py --source_path data/LLFF/room --model_path output/room_wm --ply_path output/room_reconstruct/point_cloud/iteration_20000/point_cloud.ply --checkpoint_path output/room_wm/chkpnt20000.pth
    args = parser.parse_args(sys.argv[1:])
    safe_state(args.quiet)

    calculate_rgb_metrics(
        dataset=lp.extract(args),
        opt=op.extract(args),
        pipe=pp.extract(args),
        ply_path=args.ply_path,
        checkpoint_path=args.checkpoint_path
    )

    print("\nè„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚âœ…")