import numpy as np
import torch
import os
import sys
import matplotlib.pyplot as plt
from argparse import ArgumentParser
from plyfile import PlyData
import torch.nn as nn

# ä»æ‚¨çš„é¡¹ç›®ä¸­å¯¼å…¥å¿…è¦çš„æ¨¡å—
from scene import Scene, GaussianModel
from gaussian_renderer import render
from arguments import ModelParams, OptimizationParams, PipelineParams
from utils.general_utils import safe_state

# å¯¼å…¥ç”¨äºè®¡ç®—æŒ‡æ ‡çš„åº“ (torchmetrics éå¸¸æ–¹ä¾¿)
# å¦‚æœæ²¡æœ‰å®‰è£…ï¼Œè¯·è¿è¡Œ: pip install torchmetrics
import torchmetrics
os.environ['CUDA_VISIBLE_DEVICES'] = '1'

# --- 1. è¾…åŠ©å‡½æ•°ï¼šä»æ‚¨çš„ä»£ç ä¸­å¤ç”¨PLYåŠ è½½é€»è¾‘ ---
# è¿™ä¸ªå‡½æ•°ä¸“é—¨ç”¨äºä» .ply æ–‡ä»¶åŠ è½½å¸¦æœ‰ 'semantic_' ç‰¹å¾çš„3DGSæ¨¡å‹
def load_ply_as_initialization(ply_path, dataset, opt):
    """ä»PLYæ–‡ä»¶åŠ è½½é«˜æ–¯æ¨¡å‹å‚æ•°"""
    gaussians = GaussianModel(dataset.sh_degree)

    gaussians.load_ply(ply_path)

    # # è¯»å–PLYæ–‡ä»¶æ•°æ®
    # plydata = PlyData.read(ply_path)
    # data = plydata.elements[0].data
    #
    # # è§£æPLYå±æ€§ï¼ˆéœ€ä¸å®˜æ–¹ä¿å­˜æ ¼å¼å®Œå…¨ä¸€è‡´ï¼‰
    # xyz = np.stack((data['x'], data['y'], data['z'])).transpose()
    # opacities = data['opacity'].reshape(-1, 1)
    #
    # # è§£æçƒè°ç³»æ•°
    # features_dc = np.stack([data[f'f_dc_{i}'] for i in range(3)]).transpose().reshape(-1, 3, 1)
    # features_rest = np.stack([data[f'f_rest_{i}'] for i in range(45)]).transpose().reshape(-1, 3, 15)
    #
    # # è§£æç¼©æ”¾å’Œæ—‹è½¬å‚æ•°
    # scales = np.stack([data[f'scale_{i}'] for i in range(3)]).transpose()
    # rots = np.stack([data[f'rot_{i}'] for i in range(4)]).transpose()
    #
    # # è½¬æ¢ä¸ºTensorå¹¶è®¾ç½®å¯è®­ç»ƒå‚æ•°
    # gaussians._xyz = nn.Parameter(torch.tensor(xyz, dtype=torch.float, device="cuda").requires_grad_(True))
    # gaussians._features_dc = nn.Parameter(
    #     torch.tensor(features_dc, dtype=torch.float, device="cuda").transpose(1, 2).contiguous().requires_grad_(True))
    # gaussians._features_rest = nn.Parameter(
    #     torch.tensor(features_rest, dtype=torch.float, device="cuda").transpose(1, 2).contiguous().requires_grad_(True))
    # gaussians._opacity = nn.Parameter(torch.tensor(opacities, dtype=torch.float, device="cuda").requires_grad_(True))
    # gaussians._scaling = nn.Parameter(torch.tensor(scales, dtype=torch.float, device="cuda").requires_grad_(True))
    # gaussians._rotation = nn.Parameter(torch.tensor(rots, dtype=torch.float, device="cuda").requires_grad_(True))
    #
    # # åœ¨load_ply_as_initializationå‡½æ•°æœ«å°¾æ·»åŠ 
    # gaussians.xyz_gradient_accum = torch.zeros((gaussians.get_xyz.shape[0], 1), device="cuda")
    # gaussians.denom = torch.zeros((gaussians.get_xyz.shape[0], 1), device="cuda")
    # gaussians.max_radii2D = torch.zeros((gaussians.get_xyz.shape[0]), device="cuda")

    # åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼ˆå…³é”®ï¼éœ€ä¸åŸå§‹è®­ç»ƒè®¾ç½®ä¸€è‡´ï¼‰
    gaussians.training_setup(opt)
    return gaussians

# --- 2. ä¸»è¯„ä¼°å‡½æ•° ---
def calculate_rgb_metrics(dataset, opt, pipe, ply_path):
    """
    åŠ è½½é‡å»ºçš„3DGSæ¨¡å‹ï¼Œä¸åŸå§‹æ¨¡å‹çš„æ¸²æŸ“å›¾è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶è®¡ç®—è§†è§‰è´¨é‡æŒ‡æ ‡ã€‚
    """
    print("\n[ä¿¡æ¯] æ­£åœ¨åˆå§‹åŒ–åœºæ™¯å’Œæ¨¡å‹ç”¨äºæŒ‡æ ‡è®¡ç®—...")

    # --- åœºæ™¯åŠ è½½ ---
    # æˆ‘ä»¬åŠ è½½åŸå§‹xx_wmçš„åœºæ™¯ï¼Œè¿™æ ·å°±èƒ½ç›´æ¥è®¿é—®åˆ°å®ƒçš„æ¸²æŸ“å›¾(gt_image)
    scene = Scene(dataset, GaussianModel(dataset.sh_degree), shuffle=False)

    # --- æ¨¡å‹åŠ è½½ ---
    # åŠ è½½ä½ äºŒæ¬¡è®­ç»ƒå¥½çš„ xx_reconstruct æ¨¡å‹
    print(f"\n[ä¿¡æ¯] æ­£åœ¨ä» PLY æ–‡ä»¶åŠ è½½é‡å»ºçš„ 3DGS æ¨¡å‹: {ply_path}")
    reconstructed_gaussians = load_ply_as_initialization(ply_path, dataset, opt)

    # --- è¯„ä¼°å‡†å¤‡ ---
    # è·å–æµ‹è¯•é›†ç›¸æœºè§†è§’
    test_cameras = scene.getTrainCameras()  # haha

    bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]
    background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")

    # åˆå§‹åŒ–æŒ‡æ ‡è®°å½•å˜é‡
    total_ssim, total_psnr, total_mse = 0.0, 0.0, 0.0
    num_cameras = len(test_cameras)

    print(f"\n[ä¿¡æ¯] å¼€å§‹åœ¨ {num_cameras} ä¸ªç›¸æœºè§†è§’ä¸Šè¿›è¡Œè¯„ä¼°...")

    # --- å¾ªç¯è¯„ä¼° ---
    with torch.no_grad():
        for i, viewpoint_cam in enumerate(test_cameras):
            # æ¸²æŸ“ "é‡å»ºå›¾"
            render_pkg = render(viewpoint_cam, reconstructed_gaussians, pipe, background)
            rendered_image = torch.clamp(render_pkg["render"], 0.0, 1.0)

            # è·å– "åŸºå‡†çœŸå€¼å›¾" (å³ xx_wm çš„æ¸²æŸ“å›¾)
            gt_image = torch.clamp(viewpoint_cam.original_image.to("cuda"), 0.0, 1.0)

            # ç¡®ä¿å›¾åƒå°ºå¯¸ä¸€è‡´ (æœ‰æ—¶å¯èƒ½å› æ•°æ®å¤„ç†æœ‰å¾®å°å·®å¼‚)
            if rendered_image.shape != gt_image.shape:
                gt_image = torch.nn.functional.interpolate(gt_image.unsqueeze(0),
                                                           size=rendered_image.shape[1:]).squeeze(0)

            # ä¸º torchmetrics å‡†å¤‡æ•°æ® (éœ€è¦ batch ç»´åº¦)
            rendered_batch = rendered_image.unsqueeze(0)
            gt_batch = gt_image.unsqueeze(0)

            # è®¡ç®—æŒ‡æ ‡
            ssim_val = torchmetrics.functional.structural_similarity_index_measure(rendered_batch, gt_batch,
                                                                                   data_range=1.0)
            psnr_val = torchmetrics.functional.peak_signal_noise_ratio(rendered_batch, gt_batch, data_range=1.0)
            mse_val = torch.nn.functional.mse_loss(rendered_batch, gt_batch)

            total_ssim += ssim_val.item()
            total_psnr += psnr_val.item()
            total_mse += mse_val.item()

            print(f"  è¯„ä¼°è§†è§’ {i + 1}/{num_cameras}: PSNR={psnr_val.item():.2f}, SSIM={ssim_val.item():.4f}")

            # å¯é€‰ï¼šæ˜¾ç¤ºç¬¬ä¸€å¼ å›¾çš„å¯¹æ¯”
            if i % 50 == 0:
                fig, axes = plt.subplots(1, 2, figsize=(12, 6))
                axes[0].imshow(gt_image.cpu().numpy().transpose(1, 2, 0))
                axes[0].set_title("Ground Truth Image (from xx_wm)")
                axes[0].axis('off')
                axes[1].imshow(rendered_image.cpu().numpy().transpose(1, 2, 0))
                axes[1].set_title("Reconstructed Image (from xx_reconstruct)")
                axes[1].axis('off')
                plt.show()

    # --- è®¡ç®—å¹¶æ‰“å°å¹³å‡ç»“æœ ---
    avg_ssim = total_ssim / num_cameras
    avg_psnr = total_psnr / num_cameras
    avg_mse = total_mse / num_cameras

    print("\n--- ğŸ“Š æœ€ç»ˆå¹³å‡è§†è§‰è´¨é‡æŒ‡æ ‡ ---")
    print(f"  - å¹³å‡ SSIM: {avg_ssim:.4f}  (è¶Šé«˜è¶Šå¥½, 1.0ä¸ºå®Œç¾)")
    print(f"  - å¹³å‡ PSNR: {avg_psnr:.2f} dB (è¶Šé«˜è¶Šå¥½)")
    print(f"  - å¹³å‡ MSE:  {avg_mse:.6f} (è¶Šä½è¶Šå¥½)")
    print("------------------------------------")


if __name__ == "__main__":
    # --- å‚æ•°è§£æ ---
    parser = ArgumentParser(description="è¯„ä¼°äºŒæ¬¡è®­ç»ƒå3DGSæ¨¡å‹çš„RGBé‡å»ºè´¨é‡")
    lp = ModelParams(parser)
    op = OptimizationParams(parser)
    pp = PipelineParams(parser)

    # æ·»åŠ æˆ‘ä»¬è¿™ä¸ªè„šæœ¬éœ€è¦çš„æ ¸å¿ƒå‚æ•°
    parser.add_argument("--ply_path", type=str, default="output/trex_attack/merged_gaussians/point_cloud/iteration_2000/point_cloud.ply",
                        help="æŒ‡å‘ xx_reconstruct æ¨¡å‹çš„ .ply æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--quiet", action="store_true")

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    # ä½ å¯ä»¥åƒä¸‹é¢è¿™æ ·ä»å‘½ä»¤è¡Œè¿è¡Œï¼Œæˆ–è€…ç›´æ¥åœ¨IDEä¸­é…ç½®
    # python evaluate_reconstruction.py --source_path data/LLFF/room --model_path output/room_wm --ply_path output/room_reconstruct/point_cloud/iteration_20000/point_cloud.ply
    args = parser.parse_args(sys.argv[1:])
    safe_state(args.quiet)

    # --- æ‰§è¡Œè¯„ä¼°å‡½æ•° ---
    calculate_rgb_metrics(
        dataset=lp.extract(args),
        opt=op.extract(args),
        pipe=pp.extract(args),
        ply_path=args.ply_path
    )

    print("\nè„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚âœ…")
